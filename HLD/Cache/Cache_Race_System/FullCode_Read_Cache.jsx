Perfect ğŸ‘
Below is a FULL, CLEAN, FUTURE-PROJECTâ€“READY PATCH implementation that prevents race conditions.
Iâ€™ll explain what each part does and WHY (production thinking).

ğŸš€ PATCH API â€“ Race-Condition-Safe (Node.js + MongoDB + Redis)

This setup works for:

Load-balanced servers

Distributed cache

Real production traffic

ğŸ§± Architecture (Simple)
Client
  â†“
Load Balancer
  â†“
Node.js Server (PATCH)
  â†“
Redis (Lock + Cache)
  â†“
MongoDB (Atomic Update)

1ï¸âƒ£ MongoDB Model (Atomic-friendly)
models/user.js
const mongoose = require("mongoose");

const userSchema = new mongoose.Schema({
  name: String,
  email: String,
  age: Number,
  version: {
    type: Number,
    default: 1
  }
});

module.exports = mongoose.model("User", userSchema);


ğŸ‘‰ version helps with optimistic locking

2ï¸âƒ£ Redis Client (Shared by ALL servers)
cache/redisClient.js
const redis = require("redis");

const client = redis.createClient({
  url: "redis://localhost:6379"
});

client.connect();
module.exports = client;


âœ” Same Redis used by Server-1, Server-2, Server-3
âœ” Distributed safe

3ï¸âƒ£ PATCH API (FULL PRODUCTION CODE)
routes/user.patch.js
const express = require("express");
const User = require("../models/user");
const redis = require("../cache/redisClient");

const router = express.Router();

router.patch("/users/:id", async (req, res) => {
  const userId = req.params.id;
  const lockKey = `lock:user:${userId}`;
  const cacheKey = `user:${userId}`;

  try {
    // 1ï¸âƒ£ Acquire distributed lock
    const lock = await redis.set(lockKey, "1", {
      NX: true,
      EX: 5 // auto release after 5 sec
    });

    if (!lock) {
      return res.status(409).json({
        message: "User is being updated, try again"
      });
    }

    // 2ï¸âƒ£ Atomic DB update (NO read-modify-write)
    const updatedUser = await User.findOneAndUpdate(
      { _id: userId },
      {
        $set: req.body,
        $inc: { version: 1 }
      },
      { new: true }
    );

    if (!updatedUser) {
      return res.status(404).json({ message: "User not found" });
    }

    // 3ï¸âƒ£ Invalidate cache
    await redis.del(cacheKey);

    // 4ï¸âƒ£ Release lock
    await redis.del(lockKey);

    res.json({
      message: "User updated successfully",
      data: updatedUser
    });

  } catch (err) {
    await redis.del(lockKey);
    res.status(500).json({ error: err.message });
  }
});

module.exports = router;

ğŸ§  LINE-BY-LINE WHY (IMPORTANT)
ğŸ”’ Redis Lock
SET lock:user:42 NX EX 5


âœ” Prevents multiple PATCH at same time
âœ” Works across multiple servers
âœ” Avoids race condition

âš¡ MongoDB Atomic Update
$set + $inc


âœ” No read first
âœ” No overwrite
âœ” No race condition

ğŸ§¹ Cache Invalidation
redis.del("user:42")


âœ” Prevents stale cache
âœ” Forces fresh GET next time

4ï¸âƒ£ GET API (Cache-Aside, Safe)
routes/user.get.js
router.get("/users/:id", async (req, res) => {
  const key = `user:${req.params.id}`;

  const cached = await redis.get(key);
  if (cached) {
    return res.json({ source: "cache", data: JSON.parse(cached) });
  }

  const user = await User.findById(req.params.id);
  if (!user) return res.status(404).send("Not found");

  await redis.set(key, JSON.stringify(user), { EX: 60 });

  res.json({ source: "db", data: user });
});

ğŸ§  What This Design Solves

| Problem               | Solved |
| --------------------- | ------ |
| PATCH race condition  | âœ…      |
| Lost updates          | âœ…      |
| Load-balanced servers | âœ…      |
| Stale cache           | âœ…      |
| High concurrency      | âœ…      |



ğŸ”¥ Interview-Ready Explanation

â€œFor PATCH APIs, I prevent race conditions by using Redis distributed locks and MongoDB atomic updates. I also invalidate cache after successful updates to ensure consistency in load-balanced environments.â€

ğŸŸ¢ Golden Rule (Remember Forever)

PATCH + concurrency â‡’ Atomic DB update + Lock + Cache invalidation

If you want next:

PATCH without Redis (only DB)

PATCH with ETag (If-Match)

PATCH vs PUT (interview deep dive)

Failure scenarios (lock timeout, crash)




