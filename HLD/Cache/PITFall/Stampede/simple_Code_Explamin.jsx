Perfect! Letâ€™s explain Cache Stampede prevention in GET methods with simple, practical code using Node.js + Redis, so itâ€™s interview-ready and production-friendly.

ğŸ˜ Cache Stampede Prevention in GET

Goal:
Prevent many requests from hitting the DB at the same time when cache expires.

ğŸ”¹ 1ï¸âƒ£ Concept

Normal GET (Problem):

Cache miss â†’ Many requests â†’ DB overload


Solution (Stampede Prevention):

One request rebuilds cache

Others wait or return stale cache

Redis lock used to control concurrency

ğŸ”¹ 2ï¸âƒ£ Simple Code (Node.js + Redis)
const express = require("express");
const redis = require("./redisClient");
const Product = require("./models/product"); // MongoDB model

const router = express.Router();

router.get("/products", async (req, res) => {
  const cacheKey = "products:list";
  const lockKey = "lock:products:list";

  try {
    // 1ï¸âƒ£ Try to read cache
    const cached = await redis.get(cacheKey);
    if (cached) return res.json({ source: "cache", data: JSON.parse(cached) });

    // 2ï¸âƒ£ Acquire Redis lock to prevent stampede
    const lock = await redis.set(lockKey, "1", { NX: true, EX: 5 });

    if (!lock) {
      // Another request is rebuilding cache
      // Option 1: wait a bit and retry
      // Option 2: return stale data (if available)
      return res.status(429).json({ message: "Cache rebuilding, try again" });
    }

    // 3ï¸âƒ£ Fetch from DB
    const products = await Product.find();

    // 4ï¸âƒ£ Save to cache
    await redis.set(cacheKey, JSON.stringify(products), { EX: 60 });

    // 5ï¸âƒ£ Release lock
    await redis.del(lockKey);

    res.json({ source: "db", data: products });
  } catch (err) {
    await redis.del(lockKey); // Ensure lock released on error
    res.status(500).json({ error: err.message });
  }
});

module.exports = router;

ğŸ”¹ 3ï¸âƒ£ How It Works Step-by-Step

Client GETs /products

Server checks cache:

If exists â†’ return âœ…

If not â†’ go to step 3

Server tries to acquire Redis lock:

Lock success â†’ rebuild cache from DB

Lock fails â†’ another server is rebuilding â†’ wait or return â€œtry againâ€

Cache updated â†’ lock released

Future GETs hit fresh cache

ğŸ”¹ 4ï¸âƒ£ Why This Prevents Stampede

Only one request fetches DB at a time

Others donâ€™t overwhelm DB

Lock automatically expires (EX: 5 sec)

Works in multi-server environments

ğŸ”¹ 5ï¸âƒ£ Extra Tips (Production Ready)

TTL jitter: Add random seconds to cache expiration to avoid many keys expiring together

Return stale cache instead of error â†’ better UX

Use queue or promise wait instead of 429 in high traffic

ğŸ”¹ 6ï¸âƒ£ Simple Real-Life Analogy

Cache = water tank

DB = underground water source

Lock = one person refilling tank

Others wait â†’ tank doesnâ€™t overflow the source

âœ… Golden Interview Line

â€œCache stampede occurs when many GET requests hit the DB after cache expires. We prevent it using a distributed lock so only one request rebuilds the cache while others wait or use stale data.â€

If you want, I can make a next-level version showing:

L1 + L2 cache + stampede prevention

Returning stale cache instead of error

Perfect for high-traffic production GET APIs


