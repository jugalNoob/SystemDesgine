Perfect! Letâ€™s explain Cache Avalanche in a simple, interview-ready way with why it happens, why itâ€™s important, and a simple Node.js + Redis mitigation example.

ğŸ”¹ Cache Avalanche â€“ Simple Explanation
ğŸ§  What is it?

A Cache Avalanche happens when many cache keys expire at the same time, causing a sudden surge of requests to the database.

Can crash the database

Can slow down the system

Often happens with short TTLs set uniformly

Think:

â€œ1 million usersâ€™ cache expires at 12:00 â†’ all hit DB â†’ DB overloaded.â€

âš ï¸ Why is it important?

Prevents DB overload / downtime

Ensures system stability under heavy traffic

Critical in high-read systems like e-commerce, social media, ticketing

ğŸ”¹ Example Scenario

Redis TTL = 1 hour for all hot products

All TTLs expire at exactly 12:00

Millions of users request products â†’ DB crash

ğŸ”¹ How to Prevent Cache Avalanche
1ï¸âƒ£ Randomize TTL

Add random extra seconds to TTL

Avoid all keys expiring simultaneously

2ï¸âƒ£ Preload Cache

Refresh hot keys before they expire

3ï¸âƒ£ Locking / Request Queue

First request populates cache, others wait

4ï¸âƒ£ Stagger Expiration

Set different TTLs for different keys

ğŸ”¹ Simple Node.js + Redis Example (Randomized TTL)
const redis = require("redis");
const client = redis.createClient();

async function getProduct(productId) {
  const cacheKey = `product:${productId}`;

  // 1. Try cache
  let data = await client.get(cacheKey);
  if (data) return JSON.parse(data);

  // 2. Fetch from DB
  data = await db.getProduct(productId);

  // 3. Cache with randomized TTL (avoid avalanche)
  const ttl = 3600 + Math.floor(Math.random() * 300); // 1 hour + 0-5 min random
  await client.set(cacheKey, JSON.stringify(data), { EX: ttl });

  return data;
}

âœ… How it works

Each key expires at slightly different times

Avoids all requests hitting DB at once

Reduces risk of database overload

ğŸ”¹ Interview Answer (Simple)

â€œCache avalanche occurs when many cache keys expire simultaneously, causing a surge of requests to the database.
We prevent it using randomized TTLs, cache preloading, and request locking.â€

ğŸ”¹ Quick Comparison: Stampede vs Penetration vs Avalanche



| Issue           | Meaning                            | Prevention                                |
| --------------- | ---------------------------------- | ----------------------------------------- |
| **Stampede**    | Many requests hit **missing key**  | Locking, request coalescing               |
| **Penetration** | Requests for **non-existent data** | Cache nulls, validate input, Bloom Filter |
| **Avalanche**   | Many keys expire **at same time**  | Random TTL, preload, stagger expiration   |


