üîπ Redis System Design Interview Questions
1Ô∏è‚É£ Q: How would you design a caching layer for a high-traffic website?

A:

Identify read-heavy endpoints

Choose a caching pattern (Cache-aside / Read-through)

Set TTL and eviction policy (LRU / LFU)

Handle cache invalidation (on POST/PUT/DELETE)

Plan for scaling: Redis Cluster / Sharding / Replication

Handle failover: fallback to DB if Redis is down

Example: Product catalog, leaderboard, user profiles

2Ô∏è‚É£ Q: How do you scale Redis for millions of users?

A:

Sharding: Split keys across multiple Redis nodes

Replication: Master ‚Üí replicas for read scaling

Cluster mode: High availability and partitioning

Persistence: RDB or AOF for recovery

Use consistent hashing to distribute keys

Interview tip: Always mention read vs write scaling

3Ô∏è‚É£ Q: How would you handle hot keys?

A:

Hot key = very popular key accessed repeatedly
Solutions:

Cache early / preload

Use local in-memory cache for hot keys

Use request throttling or rate limiting

Replication / multiple Redis instances

Example: ‚ÄúTrending products on Amazon‚Äù

4Ô∏è‚É£ Q: How do you handle cache invalidation in distributed systems?

A:

Manual invalidation on write (POST/PUT/DELETE)

Event-driven invalidation using message queues

TTL / expiration for automatic cleanup

Use versioning or ETags to validate cache

Tip: Mention trade-off between performance and consistency

5Ô∏è‚É£ Q: What Redis eviction policies would you use in production?

A:

LRU (Least Recently Used) ‚Äì default for memory-limited cache

LFU (Least Frequently Used) ‚Äì for frequently accessed data

TTL / Expiration ‚Äì auto remove old keys

Random ‚Äì for non-critical caches

Example: Session store ‚Üí LRU, Analytics ‚Üí LFU

6Ô∏è‚É£ Q: How would you prevent cache stampede?

A:

Use locking / mutex ‚Üí only one request repopulates cache

Randomized TTL to avoid simultaneous expirations

Request coalescing ‚Üí queue similar requests

Example: Flash sale product page

7Ô∏è‚É£ Q: How would you prevent cache penetration?

A:

Cache empty / null values with short TTL

Input validation ‚Üí reject invalid IDs

Bloom Filter ‚Üí probabilistic filter for valid keys

Example: Fake product IDs hitting DB

8Ô∏è‚É£ Q: How do you handle cache failures?

A:

Application falls back to database (graceful degradation)

Ensure retry mechanism or circuit breaker

Avoid system crashes due to cache unavailability

Tip: Interviewers check your fault-tolerance awareness

9Ô∏è‚É£ Q: How do you decide what TTL to set?

A:

Depends on data volatility and criticality

Hot read-heavy data ‚Üí longer TTL

Frequently updated data ‚Üí shorter TTL

Randomize TTL to avoid cache avalanche

üîü Q: How would you design a leaderboard or counter system using Redis?

A:

Use Sorted Sets (ZSET) for leaderboard

Use INCR / INCRBY for counters

Apply TTL if temporary

For high traffic, use sharding and replication

Example: Gaming leaderboard, social media likes

üèóÔ∏è Bonus: Redis in Node.js Production ‚Äì Key Patterns



| Pattern           | Use Case            | Node.js Implementation       |
| ----------------- | ------------------- | ---------------------------- |
| Cache-aside       | Product catalog     | Check Redis ‚Üí DB ‚Üí Redis     |
| Write-through     | User settings       | Write to Redis + DB together |
| Write-behind      | Likes / counters    | Redis first, DB later        |
| Session store     | Auth                | Store JWT/session in Redis   |
| Rate limiting     | API throttling      | Redis INCR + TTL             |
| Pub/Sub           | Notifications       | Redis channels for events    |
| Distributed locks | Payment / cron jobs | Redis SETNX / Redlock        |



üß† Interview Tips

Always mention scalability, fault-tolerance, consistency

Discuss trade-offs (performance vs consistency vs complexity)

Give real-world examples like Amazon, Netflix, Twitter